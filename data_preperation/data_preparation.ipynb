{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad575cfd",
   "metadata": {},
   "source": [
    "# Aufgabenstellung 1: Erstellen eines Prognosemodells des Kreditkartenzahlungsverkehr für Online-Einkäufe\n",
    "\n",
    "## Beschreibung der Fallstudie:\n",
    "Bereits an Deinem allerersten Tag als Data Scientist bei einem der weltweit größten Einzelhandelsunternehmen wirst Du zu einem Treffen mit Experten für Onlinezahlungen eingeladen, die Dich um Unterstützung bitten. Im letzten Jahr war die Ausfallsrate an Online-Kreditkartenzahlungen besonders hoch. Wegen dieser vielen fehlgeschlagenen Online-Überweisungen verliert das Unternehmen einerseits sehr viel Geld und andererseits werden die Kunden zunehmend unzufrieden mit dem Online-Shop des Unternehmens. Online-Kreditkartenzahlungen werden mithilfe sogenannter Zahlungsdienstleister, abgekürzt als „PSPs“ (=payments service providers), durchgeführt. Dein neuer Arbeitgeber hat mit vier verschiedenen Zahlungsdienstleistern Verträge abgeschlossen und muss für jede einzelne Überweisung Servicegebühren an diese Unternehmen zahlen. Die Logik, welcher PSP für eine bestimmte Überweisung am geeignetsten ist, basiert aktuell auf einem fixen Regelwerk und wird manuell durchgeführt. Die Entscheidungsträger innerhalb des Fachbereichs für Online- Zahlungen sind aber der Überzeugung, dass ein Prognosemodell zu besseren Entscheidungen, als ein fixes, manuelles Regelwerk, führen kann.\n",
    "\n",
    "## Ziel des Projekts:\n",
    "Unterstütze den Fachbereich für Online-Zahlungen durch ein Prognosemodell, um die Zuweisung einer Kreditkartenzahlung zu einem PSP zu automatisieren. Das Modell soll  einerseits die Erfolgsrate der Transaktionen erhöhen und andererseits die Transaktionskosten geringhalten.\n",
    "\n",
    "## Datensatz:\n",
    "Der Datensatz und weiterführende Informationen aus dem Fachbereich (Name der Zahlungsdienstleister („PSPs“), Transaktionsgebühren) sind in einem separaten zip-Dokument hinterlegt, das zum Kursmaterial angehängt wird.\n",
    "\n",
    "Daten : PSP_Jan_Feb_2019.xlsx - Liste an Kreditkartentransaktionen der DACH Länder (Deutschland, Österreich, Schweiz)\n",
    "\n",
    "## Detaillierte Beschreibung der Aufgabe:\n",
    "Die Aufgabe besteht sowohl aus einem Programmierteil als auch aus konzeptionellen Teilaufgaben. Hier folgt eine detaillierte Beschreibung an offenen Fragen, die im finalen Dokument beantwortet werden sollen:\n",
    "* Organisiere das Projekt mithilfe der CRISP-DM oder der MS Team Data Science Methode. Mache einen Vorschlag, wie die Ordnerstruktur eines Git-Repositories für das Projekt aufgebaut werden soll. Beachte, dass Du den finalen Code des Projekts nicht nach dieser Ordnerstruktur aufbauen musst.\n",
    "* Beurteile die Qualität des zur Verfügung gestellten Datensatzes. Bereite Deine Erkenntnisse so auf und visualisiere sie so, dass Businesspartner in einer klaren und einfachen Weise die wichtigen Zusammenhänge verstehen können.\n",
    "* Stelle ein erstes Basismodell (ein sogenanntes Baseline-Modell) auf, sowie ein präzises Vorhersagemodell, das den Businessanforderungen genügt, nämlich die Erfolgsrate der Kreditkartenzahlungen zu erhöhen und gleichzeitig die Transaktionskosten gering zu halten.\n",
    "* Damit die Businesspartner Vertrauen in Dein neues Modell entwickeln, solltest du die Wichtigkeit der einzelnen erklärenden Variablen diskutieren und die Modellresultate so interpretierbar wie möglich gestalten. Außerdem ist eine detaillierte Fehleranalyse sehr wichtig, damit die Businesspartner auch die Schwachstellen Deiner Herangehensweise verstehen.\n",
    "* Im letzten Schritt des Projekts soll ein Vorschlag unterbreitet werden, wie Dein Modell in die tägliche Arbeit des Fachbereichs eingebunden werden kann, beispielsweise wie eine graphische Benutzeroberfläche (GUI) aussehen könnte.\n",
    "Aufgabenstellung\n",
    "\n",
    "## Weiterführende Informationen\n",
    "\n",
    "### Spaltenbeschreibung\n",
    "\n",
    "• **tmsp**: Zeitstempel der Überweisung/Transaktion\n",
    "\n",
    "• **country**: Land der Überweisung\n",
    "\n",
    "• **amount**: Überweisungsbetrag\n",
    "\n",
    "• **success**: wenn “1”, dann ist die Überweisung erfolgreich\n",
    "\n",
    "• **PSP**: Name des Zahlungsdienstleisters (PSP = payments service provider)\n",
    "\n",
    "• **3D_secured**: wenn “1”, dann ist der Kunde 3D-identifiziert (dadurch eine noch sicherere Online-Kreditkartenzahlung)\n",
    "\n",
    "• **card**: Kreditkartenanbieter (Master, Visa, Diners)\n",
    "\n",
    "### Kosten\n",
    "\n",
    "| Name       | Gebühr erfolgreiche Transaktionen | Gebühr fehlgeschlagene Transaktionen |\n",
    "| ---------- | --------------------------------- | ------------------------------------ |\n",
    "| Moneycard  | 5 €                               | 2 €                                  |\n",
    "| Goldcard   | 10 €                              | 5 €                                  |\n",
    "| UK\\_Card   | 3 €                               | 1 €                                  |\n",
    "| Simplecard | 1 €                               | 0,5 €                                |\n",
    "\n",
    "\n",
    "### Weiterführende Informationen von geschäftlicher Seite\n",
    "\n",
    "Oftmals scheitern Überweisungen beim ersten Mal. Deshalb versuchen viele Kunden, ein und dieselbe Überweisung öfters zu tätigen. Wenn zwei Überweisungen in derselben Minute, aus demselben Land und mit demselben Überweisungsbetrag stattfinden, dann ist (für eine angemessene Anzahl an Überweisungsversuchen) davon auszugehen, dass es sich um denselben Zahlungsversuch für einen Einkauf handelt. Berücksichtige beim Entwickeln eines Machine-Learning Modells diesen Fall von mehreren Zahlungsversuchen für denselben Einkauf!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01783e88",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f8eca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardbibliothek\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Drittanbieter-Pakete\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "from holidays import Germany\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ccc427",
   "metadata": {},
   "source": [
    "# Daten untersuchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e545798",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path   = Path(r\"../Data/PSP_Jan_Feb_2019.xlsx\")\n",
    "df = pd.read_excel(raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3d976a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Dataframe hat 8 Spalten und 50410 Zeilen.\n",
      "\n",
      "der Dataframe sieht in den ersten drei Zeilen wie folgt aus :\n",
      " |   Unnamed: 0 | tmsp                | country   |   amount |   success | PSP     |   3D_secured | card   |\n",
      "|--------------|---------------------|-----------|----------|-----------|---------|--------------|--------|\n",
      "|            0 | 2019-01-01 00:01:11 | Germany   |       89 |         0 | UK_Card |            0 | Visa   |\n",
      "|            1 | 2019-01-01 00:01:17 | Germany   |       89 |         1 | UK_Card |            0 | Visa   |\n",
      "|            2 | 2019-01-01 00:02:49 | Germany   |      238 |         0 | UK_Card |            1 | Diners |. \n",
      "\n",
      "Der Dataframe komplett hat folgende Anzahl an Duplikaten: 0.\n",
      "Der DataFrame ohne 'Unnamed: 0' hat folgende Anzahl an Duplikaten: 81.\n",
      "Nach Entfernen der Duplikate: 0 Duplikate verbleibend.\n",
      "Neuer DataFrame hat 50329 Zeilen.\n",
      "Die Anzahl der fehlenden Werte entsprint: 0.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Zeilen und Spalten\n",
    "print(f\"Der Dataframe hat {df.shape[1]} Spalten und {df.shape[0]} Zeilen.\\n\")\n",
    "\n",
    "# Vorschau\n",
    "preview = tabulate(df.head(3), headers=\"keys\", tablefmt=\"github\", showindex=False)\n",
    "print(f\"der Dataframe sieht in den ersten drei Zeilen wie folgt aus :\\n {preview}. \\n\")\n",
    "\n",
    "\n",
    "# Duplikate - Index unnamed : 0 weglassen, um alle Duplikate in den relevanten Zeilen zu prüfen\n",
    "print(f\"Der Dataframe komplett hat folgende Anzahl an Duplikaten: {df.duplicated().sum()}.\") \n",
    "df_no_index = df.drop(columns=[\"Unnamed: 0\"], errors=\"ignore\")\n",
    "dup_count = df_no_index.duplicated().sum()\n",
    "print(f\"Der DataFrame ohne 'Unnamed: 0' hat folgende Anzahl an Duplikaten: {dup_count}.\")\n",
    "subset_cols = [c for c in df.columns if c != \"Unnamed: 0\"]\n",
    "df = df.drop_duplicates(subset=subset_cols, keep=\"first\").reset_index(drop=True)\n",
    "dup_count_after = df.duplicated(subset=subset_cols).sum()\n",
    "print(f\"Nach Entfernen der Duplikate: {dup_count_after} Duplikate verbleibend.\")\n",
    "print(f\"Neuer DataFrame hat {df.shape[0]} Zeilen.\")\n",
    "\n",
    "# Fehlende Werte\n",
    "print(f\"Die Anzahl der fehlenden Werte entsprint: {df.isna().sum().sum()}.\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1aa4b3",
   "metadata": {},
   "source": [
    "- Es gibt die Spalten Unnamed: 0 , tmsp, country, amount, success, PSP,3D_secured, card\n",
    "- Es gab 81 Duplikate, welche entfernt wurden.\n",
    "- Es gibt keine fehlende Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68112e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Datentypen der Spalten sind wie folgt: \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50329 entries, 0 to 50328\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   Unnamed: 0  50329 non-null  int64         \n",
      " 1   tmsp        50329 non-null  datetime64[ns]\n",
      " 2   country     50329 non-null  object        \n",
      " 3   amount      50329 non-null  int64         \n",
      " 4   success     50329 non-null  int64         \n",
      " 5   PSP         50329 non-null  object        \n",
      " 6   3D_secured  50329 non-null  int64         \n",
      " 7   card        50329 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(4), object(3)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Datentypen betrachten und prüfen, ob sie mit denen übereinstimmen, die für Sie Sinne rgeben\n",
    "\n",
    "print(f\"Die Datentypen der Spalten sind wie folgt: \\n\" )\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01890bb0",
   "metadata": {},
   "source": [
    "- Die Datentypen passen zu den erwarteten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "146602ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Die statistischen Werte der Spalte amount sind : \n",
      " count    50329.00\n",
      "mean       202.38\n",
      "std         96.26\n",
      "min          6.00\n",
      "25%        133.00\n",
      "50%        201.00\n",
      "75%        269.00\n",
      "max        630.00\n",
      "Name: amount, dtype: float64.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Amount nach Verteilung und Ausreißern anschauen\n",
    "print(f\"\\n Die statistischen Werte der Spalte amount sind : \\n {df['amount'].describe().round(2)}.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcef1591",
   "metadata": {},
   "source": [
    "Die Verteilung der Transaktionsbeträge ist weitgehend symmetrisch, da der Mittelwert (202.38€) und der Median (201.00€) fast identisch sind. Die Daten weisen jedoch mit einer Standardabweichung von 96.26€ eine erhebliche Streuung auf, wobei die Hälfte aller Transaktionen in einem Bereich zwischen 133€ und 269€ liegt. Die Beträge decken eine große Bandbreite von 6€ bis zu einem Maximum von 630€ ab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50b4c6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Einträge in 'country': 3\n",
      "| country     | Anteil   |\n",
      "|-------------|----------|\n",
      "| Germany     | 59.97%   |\n",
      "| Switzerland | 20.51%   |\n",
      "| Austria     | 19.51%   |\n",
      "\n",
      "Unique Einträge in 'success': 2\n",
      "|   success | Anteil   |\n",
      "|-----------|----------|\n",
      "|         0 | 79.68%   |\n",
      "|         1 | 20.32%   |\n",
      "\n",
      "Unique Einträge in 'PSP': 4\n",
      "| PSP        | Anteil   |\n",
      "|------------|----------|\n",
      "| UK_Card    | 52.43%   |\n",
      "| Simplecard | 24.72%   |\n",
      "| Moneycard  | 16.48%   |\n",
      "| Goldcard   | 6.37%    |\n",
      "\n",
      "Unique Einträge in '3D_secured': 2\n",
      "|   3D_secured | Anteil   |\n",
      "|--------------|----------|\n",
      "|            0 | 76.17%   |\n",
      "|            1 | 23.83%   |\n",
      "\n",
      "Unique Einträge in 'card': 3\n",
      "| card   | Anteil   |\n",
      "|--------|----------|\n",
      "| Master | 57.52%   |\n",
      "| Visa   | 23.10%   |\n",
      "| Diners | 19.38%   |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Kategorien betrachten und schauen, ob irgendwo ein Eintrag ist, der so nicht sinnvoll ist\n",
    "ausgabe_bis_cat = 30\n",
    "non_numeric_columns = [\"country\", \"success\", \"PSP\", \"3D_secured\", \"card\"]  \n",
    "\n",
    "for col in non_numeric_columns:\n",
    "    if col not in df.columns:\n",
    "        print(f\"Spalte '{col}' nicht vorhanden.\\n\")\n",
    "        continue\n",
    "\n",
    "    total = df[col].notna().sum()\n",
    "    vc = df[col].value_counts(dropna=True)\n",
    "\n",
    "    if len(vc) <= ausgabe_bis_cat:\n",
    "        print(f\"Unique Einträge in '{col}': {len(vc)}\")\n",
    "        table = [(idx, f\"{cnt / total * 100:.2f}%\") for idx, cnt in vc.items()]\n",
    "        print(tabulate(table, headers=[col, \"Anteil\"], tablefmt=\"github\"))\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"Unique Einträge in '{col}': {len(vc)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8d11e9",
   "metadata": {},
   "source": [
    "Die Ausprägungen aller kategorialen Spalten sind durchweg plausibel und entsprechen den Erwartungen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2c29cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyse für Datetime-Spalte: tmsp ---\n",
      "\n",
      "Anteil pro Jahr (%):\n",
      "tmsp\n",
      "2019    100.0 %\n",
      "Name: count, dtype: object\n",
      "\n",
      "Anteil pro Monat (%):\n",
      "tmsp\n",
      "1    52.2 %\n",
      "2    47.8 %\n",
      "Name: count, dtype: object\n",
      "\n",
      "Anteil pro Wochentag (%):\n",
      "tmsp\n",
      "0    14.49 %\n",
      "1    17.18 %\n",
      "2    16.26 %\n",
      "3    15.47 %\n",
      "4    13.68 %\n",
      "5    12.36 %\n",
      "6    10.55 %\n",
      "Name: count, dtype: object\n",
      "\n",
      "Anteil pro Stunde (0-23) (%):\n",
      "tmsp\n",
      "0     4.13 %\n",
      "1     4.15 %\n",
      "2     4.23 %\n",
      "3     4.33 %\n",
      "4     4.03 %\n",
      "5     4.23 %\n",
      "6      4.1 %\n",
      "7     4.14 %\n",
      "8      4.1 %\n",
      "9     4.12 %\n",
      "10    4.25 %\n",
      "11    4.16 %\n",
      "12    4.15 %\n",
      "13    4.25 %\n",
      "14    4.08 %\n",
      "15    4.18 %\n",
      "16    4.27 %\n",
      "17    4.21 %\n",
      "18    4.04 %\n",
      "19     4.1 %\n",
      "20    4.33 %\n",
      "21    4.21 %\n",
      "22    4.08 %\n",
      "23    4.14 %\n",
      "Name: count, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Datetime Spalte betrachten, ob die Werte den erwarteten entsprechen und ob es ungewöhnliche Verteilungen gibt Sicherstellen, \n",
    "# dass die Spalte wirklich Datetime ist\n",
    "datetime_cols = [\"tmsp\"]                    \n",
    "\n",
    "for col in datetime_cols:\n",
    "    print(f\"\\n--- Analyse für Datetime-Spalte: {col} ---\")\n",
    "    \n",
    "    series = df[col].dropna()\n",
    "    total   = series.size                 \n",
    "\n",
    "    def pct(counts):\n",
    "        return (counts / total * 100).round(2)  \n",
    "\n",
    "    print(\"\\nAnteil pro Jahr (%):\")\n",
    "    print(pct(series.dt.year.value_counts().sort_index()).astype(str) + \" %\")\n",
    "\n",
    "    print(\"\\nAnteil pro Monat (%):\")\n",
    "    print(pct(series.dt.month.value_counts().sort_index()).astype(str) + \" %\")\n",
    "\n",
    "    print(\"\\nAnteil pro Wochentag (%):\")\n",
    "    print(pct(series.dt.dayofweek.value_counts().sort_index()).astype(str) + \" %\")\n",
    "\n",
    "    if series.dt.hour.notna().any():\n",
    "        print(\"\\nAnteil pro Stunde (0-23) (%):\")\n",
    "        print(pct(series.dt.hour.value_counts().sort_index()).astype(str) + \" %\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7360725",
   "metadata": {},
   "source": [
    "Die Analyse der Zeitstempel-Spalte `tmsp` zeigt, dass alle Transaktionen aus dem Jahr 2019 stammen und sich relativ gleichmäßig auf die Monate Januar (52,2 %) und Februar (47,8 %) verteilen. Innerhalb der Woche ist die Transaktionsaktivität an den Werktagen höher, mit einem Höhepunkt am Dienstag (17,2 %), und nimmt zum Wochenende hin, insbesondere am Sonntag (10,6 %), deutlich ab. Über den Tagesverlauf sind die Transaktionen hingegen sehr gleichmäßig verteilt, da jede Stunde einen annähernd gleichen Anteil von etwa 4 % am Gesamtvolumen hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b940ee27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50329 entries, 0 to 50328\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   Unnamed: 0  50329 non-null  int64         \n",
      " 1   tmsp        50329 non-null  datetime64[ns]\n",
      " 2   country     50329 non-null  object        \n",
      " 3   amount      50329 non-null  int64         \n",
      " 4   success     50329 non-null  int64         \n",
      " 5   PSP         50329 non-null  object        \n",
      " 6   3D_secured  50329 non-null  int64         \n",
      " 7   card        50329 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(4), object(3)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b4a345",
   "metadata": {},
   "source": [
    "# Dataframe ohne Duplikate speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d198a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exists: True\n"
     ]
    }
   ],
   "source": [
    "this_dir = Path.cwd()         #/data_analysis\n",
    "data_dir   = this_dir / \"..\" / \"Data\"               # …/Data   \n",
    "data_dir   = data_dir.resolve()                     # in absoluten Pfad umwandeln\n",
    "pkl_path   = data_dir / \"df_original.pkl\"     # /Data/df_oridinal.pkl\n",
    "\n",
    "df.to_pickle(pkl_path)\n",
    "\n",
    "# Überprüfen\n",
    "print(\"Exists:\", os.path.exists(pkl_path))\n",
    "#print(pkl_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
